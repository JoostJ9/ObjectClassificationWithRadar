{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1413a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "INSHEP = pd.read_csv(r'C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassificationWithRadar\\Training_with_our_features\\INSHEP_features.csv')\n",
    "SPECTROGRAM = pd.read_csv(r'C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassificationWithRadar\\Training_with_transfer_learning\\spectrogram_features_google_vite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586db8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>path</th>\n",
       "      <th>mean_entropy</th>\n",
       "      <th>mean_power</th>\n",
       "      <th>variance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>max_vel</th>\n",
       "      <th>amp_density</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_torso_power</th>\n",
       "      <th>pos_neg_ratio</th>\n",
       "      <th>doppler_offset</th>\n",
       "      <th>main_lobe_width</th>\n",
       "      <th>motion_duration</th>\n",
       "      <th>doppler_peak_velocity</th>\n",
       "      <th>doppler_symmetry_index</th>\n",
       "      <th>cepstral_entropy</th>\n",
       "      <th>range_bin_span</th>\n",
       "      <th>doppler_bandwidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1P36A01R02</td>\n",
       "      <td>walking</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>9.025276</td>\n",
       "      <td>1.959870e+07</td>\n",
       "      <td>6.906348e+16</td>\n",
       "      <td>2.627993e+08</td>\n",
       "      <td>1.099138</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>721.726235</td>\n",
       "      <td>...</td>\n",
       "      <td>7.179115e+07</td>\n",
       "      <td>1.530323</td>\n",
       "      <td>0.279423</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.002155</td>\n",
       "      <td>0.209587</td>\n",
       "      <td>0.940833</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.836027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1P38A01R03</td>\n",
       "      <td>walking</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>9.258551</td>\n",
       "      <td>2.104924e+07</td>\n",
       "      <td>5.631026e+16</td>\n",
       "      <td>2.372978e+08</td>\n",
       "      <td>0.840517</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>433.210982</td>\n",
       "      <td>...</td>\n",
       "      <td>6.311644e+07</td>\n",
       "      <td>1.251952</td>\n",
       "      <td>0.112505</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.111882</td>\n",
       "      <td>0.999645</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.915421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1P38A01R01</td>\n",
       "      <td>walking</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>9.140249</td>\n",
       "      <td>2.620588e+07</td>\n",
       "      <td>9.122603e+16</td>\n",
       "      <td>3.020365e+08</td>\n",
       "      <td>0.808190</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>421.248890</td>\n",
       "      <td>...</td>\n",
       "      <td>1.433929e+08</td>\n",
       "      <td>1.574890</td>\n",
       "      <td>0.182513</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.840517</td>\n",
       "      <td>0.223268</td>\n",
       "      <td>1.032866</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.705764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1P37A01R02</td>\n",
       "      <td>walking</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>9.187234</td>\n",
       "      <td>2.411605e+07</td>\n",
       "      <td>7.596749e+16</td>\n",
       "      <td>2.756220e+08</td>\n",
       "      <td>0.840517</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>389.177448</td>\n",
       "      <td>...</td>\n",
       "      <td>1.239555e+08</td>\n",
       "      <td>0.917316</td>\n",
       "      <td>-0.039091</td>\n",
       "      <td>1.907328</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.840517</td>\n",
       "      <td>-0.043125</td>\n",
       "      <td>0.982990</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.738319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1P36A01R03</td>\n",
       "      <td>walking</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>8.914113</td>\n",
       "      <td>1.945387e+07</td>\n",
       "      <td>7.617443e+16</td>\n",
       "      <td>2.759972e+08</td>\n",
       "      <td>0.969828</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>700.990139</td>\n",
       "      <td>...</td>\n",
       "      <td>6.483077e+07</td>\n",
       "      <td>2.064459</td>\n",
       "      <td>0.364250</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.347356</td>\n",
       "      <td>0.921222</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.762972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>5P55A05R2</td>\n",
       "      <td>drink_water</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>7.935626</td>\n",
       "      <td>5.718070e+05</td>\n",
       "      <td>7.192478e+13</td>\n",
       "      <td>8.480848e+06</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>640.340498</td>\n",
       "      <td>...</td>\n",
       "      <td>2.337248e+07</td>\n",
       "      <td>0.927633</td>\n",
       "      <td>-0.015329</td>\n",
       "      <td>0.420259</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>-0.037542</td>\n",
       "      <td>0.653246</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.272728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>5P55A05R3</td>\n",
       "      <td>drink_water</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>8.041883</td>\n",
       "      <td>9.940976e+05</td>\n",
       "      <td>1.895267e+14</td>\n",
       "      <td>1.376687e+07</td>\n",
       "      <td>-0.193966</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>528.732149</td>\n",
       "      <td>...</td>\n",
       "      <td>3.984330e+07</td>\n",
       "      <td>1.403761</td>\n",
       "      <td>0.040513</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.167971</td>\n",
       "      <td>0.877308</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.242563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>5P56A05R1</td>\n",
       "      <td>drink_water</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>7.231323</td>\n",
       "      <td>2.052530e+06</td>\n",
       "      <td>1.951923e+15</td>\n",
       "      <td>4.418057e+07</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>1119.092028</td>\n",
       "      <td>...</td>\n",
       "      <td>8.719889e+07</td>\n",
       "      <td>1.275885</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.420259</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>0.121221</td>\n",
       "      <td>1.052820</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.204817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>5P56A05R2</td>\n",
       "      <td>drink_water</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>7.295752</td>\n",
       "      <td>1.713943e+06</td>\n",
       "      <td>1.355906e+15</td>\n",
       "      <td>3.682262e+07</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>1515.745649</td>\n",
       "      <td>...</td>\n",
       "      <td>6.577793e+07</td>\n",
       "      <td>1.193892</td>\n",
       "      <td>0.027241</td>\n",
       "      <td>0.484914</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>0.088378</td>\n",
       "      <td>1.140604</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.228499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>5P56A05R3</td>\n",
       "      <td>drink_water</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>7.325337</td>\n",
       "      <td>1.550412e+06</td>\n",
       "      <td>1.088354e+15</td>\n",
       "      <td>3.299020e+07</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1611.329710</td>\n",
       "      <td>...</td>\n",
       "      <td>7.025300e+07</td>\n",
       "      <td>1.729300</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>0.096983</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.267211</td>\n",
       "      <td>1.095919</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.195418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1754 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_id     activity  \\\n",
       "0     1P36A01R02      walking   \n",
       "1     1P38A01R03      walking   \n",
       "2     1P38A01R01      walking   \n",
       "3     1P37A01R02      walking   \n",
       "4     1P36A01R03      walking   \n",
       "...          ...          ...   \n",
       "1749   5P55A05R2  drink_water   \n",
       "1750   5P55A05R3  drink_water   \n",
       "1751   5P56A05R1  drink_water   \n",
       "1752   5P56A05R2  drink_water   \n",
       "1753   5P56A05R3  drink_water   \n",
       "\n",
       "                                                   path  mean_entropy  \\\n",
       "0     C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      9.025276   \n",
       "1     C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      9.258551   \n",
       "2     C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      9.140249   \n",
       "3     C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      9.187234   \n",
       "4     C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      8.914113   \n",
       "...                                                 ...           ...   \n",
       "1749  C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      7.935626   \n",
       "1750  C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      8.041883   \n",
       "1751  C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      7.231323   \n",
       "1752  C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      7.295752   \n",
       "1753  C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      7.325337   \n",
       "\n",
       "        mean_power      variance        stddev   max_vel  amp_density  \\\n",
       "0     1.959870e+07  6.906348e+16  2.627993e+08  1.099138     0.000520   \n",
       "1     2.104924e+07  5.631026e+16  2.372978e+08  0.840517     0.000819   \n",
       "2     2.620588e+07  9.122603e+16  3.020365e+08  0.808190     0.000743   \n",
       "3     2.411605e+07  7.596749e+16  2.756220e+08  0.840517     0.000945   \n",
       "4     1.945387e+07  7.617443e+16  2.759972e+08  0.969828     0.000692   \n",
       "...            ...           ...           ...       ...          ...   \n",
       "1749  5.718070e+05  7.192478e+13  8.480848e+06  0.161638     0.000559   \n",
       "1750  9.940976e+05  1.895267e+14  1.376687e+07 -0.193966     0.000572   \n",
       "1751  2.052530e+06  1.951923e+15  4.418057e+07  0.161638     0.000533   \n",
       "1752  1.713943e+06  1.355906e+15  3.682262e+07  0.193966     0.000288   \n",
       "1753  1.550412e+06  1.088354e+15  3.299020e+07  0.129310     0.000265   \n",
       "\n",
       "         kurtosis  ...  mean_torso_power  pos_neg_ratio  doppler_offset  \\\n",
       "0      721.726235  ...      7.179115e+07       1.530323        0.279423   \n",
       "1      433.210982  ...      6.311644e+07       1.251952        0.112505   \n",
       "2      421.248890  ...      1.433929e+08       1.574890        0.182513   \n",
       "3      389.177448  ...      1.239555e+08       0.917316       -0.039091   \n",
       "4      700.990139  ...      6.483077e+07       2.064459        0.364250   \n",
       "...           ...  ...               ...            ...             ...   \n",
       "1749   640.340498  ...      2.337248e+07       0.927633       -0.015329   \n",
       "1750   528.732149  ...      3.984330e+07       1.403761        0.040513   \n",
       "1751  1119.092028  ...      8.719889e+07       1.275885        0.032924   \n",
       "1752  1515.745649  ...      6.577793e+07       1.193892        0.027241   \n",
       "1753  1611.329710  ...      7.025300e+07       1.729300        0.041178   \n",
       "\n",
       "      main_lobe_width  motion_duration  doppler_peak_velocity  \\\n",
       "0            0.258621             1.07               1.002155   \n",
       "1            0.161638             2.30               0.937500   \n",
       "2            0.193966             2.00               0.840517   \n",
       "3            1.907328             2.01               0.840517   \n",
       "4            0.193966             1.37               0.905172   \n",
       "...               ...              ...                    ...   \n",
       "1749         0.420259             0.42               0.161638   \n",
       "1750         0.387931             0.59               0.129310   \n",
       "1751         0.420259             0.46               0.161638   \n",
       "1752         0.484914             0.26               0.193966   \n",
       "1753         0.096983             0.22               0.129310   \n",
       "\n",
       "      doppler_symmetry_index  cepstral_entropy  range_bin_span  \\\n",
       "0                   0.209587          0.940833             6.0   \n",
       "1                   0.111882          0.999645             6.0   \n",
       "2                   0.223268          1.032866             5.0   \n",
       "3                  -0.043125          0.982990             6.0   \n",
       "4                   0.347356          0.921222             6.0   \n",
       "...                      ...               ...             ...   \n",
       "1749               -0.037542          0.653246             3.0   \n",
       "1750                0.167971          0.877308             2.0   \n",
       "1751                0.121221          1.052820             2.0   \n",
       "1752                0.088378          1.140604             2.0   \n",
       "1753                0.267211          1.095919             2.0   \n",
       "\n",
       "      doppler_bandwidth  \n",
       "0              0.836027  \n",
       "1              0.915421  \n",
       "2              0.705764  \n",
       "3              0.738319  \n",
       "4              0.762972  \n",
       "...                 ...  \n",
       "1749           0.272728  \n",
       "1750           0.242563  \n",
       "1751           0.204817  \n",
       "1752           0.228499  \n",
       "1753           0.195418  \n",
       "\n",
       "[1754 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INSHEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f162ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, extract the folder name from the Windows-style path\n",
    "INSHEP['folder'] = INSHEP['path'].str.extract(r'datasets\\\\([^\\\\]+)\\\\')\n",
    "\n",
    "# Then, build the full image path\n",
    "INSHEP['image_path'] = 'spectrograms/' + INSHEP['folder'] + '/' + INSHEP['file_id'] + '_spectrogram.png'\n",
    "\n",
    "# Optional: drop the helper 'folder' column\n",
    "INSHEP.drop(columns=['folder'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d904fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>path</th>\n",
       "      <th>mean_entropy</th>\n",
       "      <th>mean_power</th>\n",
       "      <th>variance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>max_vel</th>\n",
       "      <th>amp_density</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_neg_ratio</th>\n",
       "      <th>doppler_offset</th>\n",
       "      <th>main_lobe_width</th>\n",
       "      <th>motion_duration</th>\n",
       "      <th>doppler_peak_velocity</th>\n",
       "      <th>doppler_symmetry_index</th>\n",
       "      <th>cepstral_entropy</th>\n",
       "      <th>range_bin_span</th>\n",
       "      <th>doppler_bandwidth</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1P36A01R02</td>\n",
       "      <td>walking</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>9.025276</td>\n",
       "      <td>1.959870e+07</td>\n",
       "      <td>6.906348e+16</td>\n",
       "      <td>2.627993e+08</td>\n",
       "      <td>1.099138</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>721.726235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.530323</td>\n",
       "      <td>0.279423</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.002155</td>\n",
       "      <td>0.209587</td>\n",
       "      <td>0.940833</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.836027</td>\n",
       "      <td>spectrograms/1 December 2017 Dataset/1P36A01R0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1P38A01R03</td>\n",
       "      <td>walking</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>9.258551</td>\n",
       "      <td>2.104924e+07</td>\n",
       "      <td>5.631026e+16</td>\n",
       "      <td>2.372978e+08</td>\n",
       "      <td>0.840517</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>433.210982</td>\n",
       "      <td>...</td>\n",
       "      <td>1.251952</td>\n",
       "      <td>0.112505</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.111882</td>\n",
       "      <td>0.999645</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.915421</td>\n",
       "      <td>spectrograms/1 December 2017 Dataset/1P38A01R0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1P38A01R01</td>\n",
       "      <td>walking</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>9.140249</td>\n",
       "      <td>2.620588e+07</td>\n",
       "      <td>9.122603e+16</td>\n",
       "      <td>3.020365e+08</td>\n",
       "      <td>0.808190</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>421.248890</td>\n",
       "      <td>...</td>\n",
       "      <td>1.574890</td>\n",
       "      <td>0.182513</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.840517</td>\n",
       "      <td>0.223268</td>\n",
       "      <td>1.032866</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.705764</td>\n",
       "      <td>spectrograms/1 December 2017 Dataset/1P38A01R0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1P37A01R02</td>\n",
       "      <td>walking</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>9.187234</td>\n",
       "      <td>2.411605e+07</td>\n",
       "      <td>7.596749e+16</td>\n",
       "      <td>2.756220e+08</td>\n",
       "      <td>0.840517</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>389.177448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917316</td>\n",
       "      <td>-0.039091</td>\n",
       "      <td>1.907328</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.840517</td>\n",
       "      <td>-0.043125</td>\n",
       "      <td>0.982990</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.738319</td>\n",
       "      <td>spectrograms/1 December 2017 Dataset/1P37A01R0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1P36A01R03</td>\n",
       "      <td>walking</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>8.914113</td>\n",
       "      <td>1.945387e+07</td>\n",
       "      <td>7.617443e+16</td>\n",
       "      <td>2.759972e+08</td>\n",
       "      <td>0.969828</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>700.990139</td>\n",
       "      <td>...</td>\n",
       "      <td>2.064459</td>\n",
       "      <td>0.364250</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.347356</td>\n",
       "      <td>0.921222</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.762972</td>\n",
       "      <td>spectrograms/1 December 2017 Dataset/1P36A01R0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>5P55A05R2</td>\n",
       "      <td>drink_water</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>7.935626</td>\n",
       "      <td>5.718070e+05</td>\n",
       "      <td>7.192478e+13</td>\n",
       "      <td>8.480848e+06</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>640.340498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927633</td>\n",
       "      <td>-0.015329</td>\n",
       "      <td>0.420259</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>-0.037542</td>\n",
       "      <td>0.653246</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.272728</td>\n",
       "      <td>spectrograms/7 March 2019 West Cumbria Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>5P55A05R3</td>\n",
       "      <td>drink_water</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>8.041883</td>\n",
       "      <td>9.940976e+05</td>\n",
       "      <td>1.895267e+14</td>\n",
       "      <td>1.376687e+07</td>\n",
       "      <td>-0.193966</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>528.732149</td>\n",
       "      <td>...</td>\n",
       "      <td>1.403761</td>\n",
       "      <td>0.040513</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.167971</td>\n",
       "      <td>0.877308</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.242563</td>\n",
       "      <td>spectrograms/7 March 2019 West Cumbria Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>5P56A05R1</td>\n",
       "      <td>drink_water</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>7.231323</td>\n",
       "      <td>2.052530e+06</td>\n",
       "      <td>1.951923e+15</td>\n",
       "      <td>4.418057e+07</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>1119.092028</td>\n",
       "      <td>...</td>\n",
       "      <td>1.275885</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.420259</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>0.121221</td>\n",
       "      <td>1.052820</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.204817</td>\n",
       "      <td>spectrograms/7 March 2019 West Cumbria Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>5P56A05R2</td>\n",
       "      <td>drink_water</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>7.295752</td>\n",
       "      <td>1.713943e+06</td>\n",
       "      <td>1.355906e+15</td>\n",
       "      <td>3.682262e+07</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>1515.745649</td>\n",
       "      <td>...</td>\n",
       "      <td>1.193892</td>\n",
       "      <td>0.027241</td>\n",
       "      <td>0.484914</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>0.088378</td>\n",
       "      <td>1.140604</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.228499</td>\n",
       "      <td>spectrograms/7 March 2019 West Cumbria Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>5P56A05R3</td>\n",
       "      <td>drink_water</td>\n",
       "      <td>C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...</td>\n",
       "      <td>7.325337</td>\n",
       "      <td>1.550412e+06</td>\n",
       "      <td>1.088354e+15</td>\n",
       "      <td>3.299020e+07</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1611.329710</td>\n",
       "      <td>...</td>\n",
       "      <td>1.729300</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>0.096983</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.267211</td>\n",
       "      <td>1.095919</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.195418</td>\n",
       "      <td>spectrograms/Sample_data_preprocessing+label_e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1754 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_id     activity  \\\n",
       "0     1P36A01R02      walking   \n",
       "1     1P38A01R03      walking   \n",
       "2     1P38A01R01      walking   \n",
       "3     1P37A01R02      walking   \n",
       "4     1P36A01R03      walking   \n",
       "...          ...          ...   \n",
       "1749   5P55A05R2  drink_water   \n",
       "1750   5P55A05R3  drink_water   \n",
       "1751   5P56A05R1  drink_water   \n",
       "1752   5P56A05R2  drink_water   \n",
       "1753   5P56A05R3  drink_water   \n",
       "\n",
       "                                                   path  mean_entropy  \\\n",
       "0     C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      9.025276   \n",
       "1     C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      9.258551   \n",
       "2     C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      9.140249   \n",
       "3     C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      9.187234   \n",
       "4     C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      8.914113   \n",
       "...                                                 ...           ...   \n",
       "1749  C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      7.935626   \n",
       "1750  C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      8.041883   \n",
       "1751  C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      7.231323   \n",
       "1752  C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      7.295752   \n",
       "1753  C:\\Users\\Adnane\\Desktop\\Radar\\ObjectClassifica...      7.325337   \n",
       "\n",
       "        mean_power      variance        stddev   max_vel  amp_density  \\\n",
       "0     1.959870e+07  6.906348e+16  2.627993e+08  1.099138     0.000520   \n",
       "1     2.104924e+07  5.631026e+16  2.372978e+08  0.840517     0.000819   \n",
       "2     2.620588e+07  9.122603e+16  3.020365e+08  0.808190     0.000743   \n",
       "3     2.411605e+07  7.596749e+16  2.756220e+08  0.840517     0.000945   \n",
       "4     1.945387e+07  7.617443e+16  2.759972e+08  0.969828     0.000692   \n",
       "...            ...           ...           ...       ...          ...   \n",
       "1749  5.718070e+05  7.192478e+13  8.480848e+06  0.161638     0.000559   \n",
       "1750  9.940976e+05  1.895267e+14  1.376687e+07 -0.193966     0.000572   \n",
       "1751  2.052530e+06  1.951923e+15  4.418057e+07  0.161638     0.000533   \n",
       "1752  1.713943e+06  1.355906e+15  3.682262e+07  0.193966     0.000288   \n",
       "1753  1.550412e+06  1.088354e+15  3.299020e+07  0.129310     0.000265   \n",
       "\n",
       "         kurtosis  ...  pos_neg_ratio  doppler_offset  main_lobe_width  \\\n",
       "0      721.726235  ...       1.530323        0.279423         0.258621   \n",
       "1      433.210982  ...       1.251952        0.112505         0.161638   \n",
       "2      421.248890  ...       1.574890        0.182513         0.193966   \n",
       "3      389.177448  ...       0.917316       -0.039091         1.907328   \n",
       "4      700.990139  ...       2.064459        0.364250         0.193966   \n",
       "...           ...  ...            ...             ...              ...   \n",
       "1749   640.340498  ...       0.927633       -0.015329         0.420259   \n",
       "1750   528.732149  ...       1.403761        0.040513         0.387931   \n",
       "1751  1119.092028  ...       1.275885        0.032924         0.420259   \n",
       "1752  1515.745649  ...       1.193892        0.027241         0.484914   \n",
       "1753  1611.329710  ...       1.729300        0.041178         0.096983   \n",
       "\n",
       "      motion_duration  doppler_peak_velocity  doppler_symmetry_index  \\\n",
       "0                1.07               1.002155                0.209587   \n",
       "1                2.30               0.937500                0.111882   \n",
       "2                2.00               0.840517                0.223268   \n",
       "3                2.01               0.840517               -0.043125   \n",
       "4                1.37               0.905172                0.347356   \n",
       "...               ...                    ...                     ...   \n",
       "1749             0.42               0.161638               -0.037542   \n",
       "1750             0.59               0.129310                0.167971   \n",
       "1751             0.46               0.161638                0.121221   \n",
       "1752             0.26               0.193966                0.088378   \n",
       "1753             0.22               0.129310                0.267211   \n",
       "\n",
       "      cepstral_entropy  range_bin_span  doppler_bandwidth  \\\n",
       "0             0.940833             6.0           0.836027   \n",
       "1             0.999645             6.0           0.915421   \n",
       "2             1.032866             5.0           0.705764   \n",
       "3             0.982990             6.0           0.738319   \n",
       "4             0.921222             6.0           0.762972   \n",
       "...                ...             ...                ...   \n",
       "1749          0.653246             3.0           0.272728   \n",
       "1750          0.877308             2.0           0.242563   \n",
       "1751          1.052820             2.0           0.204817   \n",
       "1752          1.140604             2.0           0.228499   \n",
       "1753          1.095919             2.0           0.195418   \n",
       "\n",
       "                                             image_path  \n",
       "0     spectrograms/1 December 2017 Dataset/1P36A01R0...  \n",
       "1     spectrograms/1 December 2017 Dataset/1P38A01R0...  \n",
       "2     spectrograms/1 December 2017 Dataset/1P38A01R0...  \n",
       "3     spectrograms/1 December 2017 Dataset/1P37A01R0...  \n",
       "4     spectrograms/1 December 2017 Dataset/1P36A01R0...  \n",
       "...                                                 ...  \n",
       "1749  spectrograms/7 March 2019 West Cumbria Dataset...  \n",
       "1750  spectrograms/7 March 2019 West Cumbria Dataset...  \n",
       "1751  spectrograms/7 March 2019 West Cumbria Dataset...  \n",
       "1752  spectrograms/7 March 2019 West Cumbria Dataset...  \n",
       "1753  spectrograms/Sample_data_preprocessing+label_e...  \n",
       "\n",
       "[1754 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INSHEP\n",
    "#display where path is duplicated and order by path\n",
    "INSHEP[INSHEP.duplicated(subset=['path'], keep=False)].sort_values(by='path')\n",
    "\n",
    "#remove duplicates based on 'path' column, keeping the first occurrence\n",
    "INSHEP = INSHEP.drop_duplicates(subset=['path'], keep='first')\n",
    "INSHEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c0ff5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = SPECTROGRAM.merge(INSHEP, on='image_path', how='inner')  # or 'left'/'right'/'outer' as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4d667e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_torso_power</th>\n",
       "      <th>pos_neg_ratio</th>\n",
       "      <th>doppler_offset</th>\n",
       "      <th>main_lobe_width</th>\n",
       "      <th>motion_duration</th>\n",
       "      <th>doppler_peak_velocity</th>\n",
       "      <th>doppler_symmetry_index</th>\n",
       "      <th>cepstral_entropy</th>\n",
       "      <th>range_bin_span</th>\n",
       "      <th>doppler_bandwidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spectrograms/4 July 2018 Dataset/3P66A03R2_spe...</td>\n",
       "      <td>-0.048340</td>\n",
       "      <td>0.055817</td>\n",
       "      <td>-0.145508</td>\n",
       "      <td>-0.373291</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.236084</td>\n",
       "      <td>0.068909</td>\n",
       "      <td>0.140747</td>\n",
       "      <td>-0.217529</td>\n",
       "      <td>...</td>\n",
       "      <td>6.303265e+07</td>\n",
       "      <td>0.151130</td>\n",
       "      <td>-0.231972</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.193966</td>\n",
       "      <td>-0.737423</td>\n",
       "      <td>1.083437</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.236668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spectrograms/4 July 2018 Dataset/1P68A01R1_spe...</td>\n",
       "      <td>0.034607</td>\n",
       "      <td>-0.034241</td>\n",
       "      <td>-0.101257</td>\n",
       "      <td>-0.314209</td>\n",
       "      <td>-0.255371</td>\n",
       "      <td>-0.125732</td>\n",
       "      <td>0.016068</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>-0.256104</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235783e+07</td>\n",
       "      <td>0.558474</td>\n",
       "      <td>-0.234554</td>\n",
       "      <td>0.420259</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-0.872845</td>\n",
       "      <td>-0.283306</td>\n",
       "      <td>0.909129</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.832668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spectrograms/4 July 2018 Dataset/5P60A05R1_spe...</td>\n",
       "      <td>-0.086121</td>\n",
       "      <td>0.089172</td>\n",
       "      <td>-0.174683</td>\n",
       "      <td>-0.426758</td>\n",
       "      <td>-0.082092</td>\n",
       "      <td>-0.114990</td>\n",
       "      <td>-0.052063</td>\n",
       "      <td>0.198975</td>\n",
       "      <td>-0.243286</td>\n",
       "      <td>...</td>\n",
       "      <td>1.745773e+06</td>\n",
       "      <td>1.047543</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.323276</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.023219</td>\n",
       "      <td>0.410934</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.762034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spectrograms/4 July 2018 Dataset/3P65A03R3_spe...</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>0.034851</td>\n",
       "      <td>-0.234253</td>\n",
       "      <td>-0.427246</td>\n",
       "      <td>-0.048126</td>\n",
       "      <td>-0.329834</td>\n",
       "      <td>0.031830</td>\n",
       "      <td>0.111877</td>\n",
       "      <td>-0.276123</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134535e+08</td>\n",
       "      <td>0.047521</td>\n",
       "      <td>-0.251409</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.161638</td>\n",
       "      <td>-0.909270</td>\n",
       "      <td>1.122153</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.204580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spectrograms/4 July 2018 Dataset/1P62A01R2_spe...</td>\n",
       "      <td>0.058044</td>\n",
       "      <td>-0.131958</td>\n",
       "      <td>-0.123047</td>\n",
       "      <td>-0.252197</td>\n",
       "      <td>-0.213013</td>\n",
       "      <td>-0.140991</td>\n",
       "      <td>0.030991</td>\n",
       "      <td>-0.042145</td>\n",
       "      <td>-0.204224</td>\n",
       "      <td>...</td>\n",
       "      <td>9.166222e+06</td>\n",
       "      <td>1.839353</td>\n",
       "      <td>0.272753</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.295614</td>\n",
       "      <td>0.826051</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.963742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>spectrograms/1 December 2017 Dataset/6P56A06R0...</td>\n",
       "      <td>-0.045807</td>\n",
       "      <td>-0.061523</td>\n",
       "      <td>-0.045197</td>\n",
       "      <td>-0.329102</td>\n",
       "      <td>-0.037079</td>\n",
       "      <td>-0.083801</td>\n",
       "      <td>-0.027954</td>\n",
       "      <td>0.187988</td>\n",
       "      <td>-0.169800</td>\n",
       "      <td>...</td>\n",
       "      <td>3.642903e+06</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>-0.585832</td>\n",
       "      <td>0.193966</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.517241</td>\n",
       "      <td>-0.967423</td>\n",
       "      <td>1.140569</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.293774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>spectrograms/1 December 2017 Dataset/1P42A01R0...</td>\n",
       "      <td>0.025467</td>\n",
       "      <td>-0.013214</td>\n",
       "      <td>-0.195801</td>\n",
       "      <td>-0.453125</td>\n",
       "      <td>-0.275391</td>\n",
       "      <td>-0.149902</td>\n",
       "      <td>-0.021835</td>\n",
       "      <td>0.052521</td>\n",
       "      <td>-0.262939</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031794e+08</td>\n",
       "      <td>0.648905</td>\n",
       "      <td>-0.094934</td>\n",
       "      <td>1.745690</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-0.743534</td>\n",
       "      <td>-0.212926</td>\n",
       "      <td>0.960106</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.736956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>spectrograms/1 December 2017 Dataset/6P40A06R0...</td>\n",
       "      <td>-0.044037</td>\n",
       "      <td>-0.016708</td>\n",
       "      <td>-0.088562</td>\n",
       "      <td>-0.362061</td>\n",
       "      <td>-0.119751</td>\n",
       "      <td>-0.167114</td>\n",
       "      <td>-0.026672</td>\n",
       "      <td>0.211792</td>\n",
       "      <td>-0.144775</td>\n",
       "      <td>...</td>\n",
       "      <td>1.974422e+07</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>-0.433081</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.355603</td>\n",
       "      <td>-0.971394</td>\n",
       "      <td>1.054593</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.330681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>spectrograms/1 December 2017 Dataset/2P56A02R0...</td>\n",
       "      <td>0.064026</td>\n",
       "      <td>-0.040649</td>\n",
       "      <td>-0.171021</td>\n",
       "      <td>-0.335693</td>\n",
       "      <td>-0.171387</td>\n",
       "      <td>-0.112244</td>\n",
       "      <td>-0.003649</td>\n",
       "      <td>0.106323</td>\n",
       "      <td>-0.143188</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168200e+08</td>\n",
       "      <td>15.373221</td>\n",
       "      <td>0.264797</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.161638</td>\n",
       "      <td>0.877849</td>\n",
       "      <td>1.310697</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.270219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>spectrograms/Sample_data_preprocessing+label_e...</td>\n",
       "      <td>0.089233</td>\n",
       "      <td>0.015251</td>\n",
       "      <td>-0.126831</td>\n",
       "      <td>-0.284668</td>\n",
       "      <td>-0.037140</td>\n",
       "      <td>-0.150513</td>\n",
       "      <td>0.018188</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>-0.143188</td>\n",
       "      <td>...</td>\n",
       "      <td>7.025300e+07</td>\n",
       "      <td>1.729300</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>0.096983</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.267211</td>\n",
       "      <td>1.095919</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.195418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1754 rows × 791 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path  feature_0  feature_1  \\\n",
       "0     spectrograms/4 July 2018 Dataset/3P66A03R2_spe...  -0.048340   0.055817   \n",
       "1     spectrograms/4 July 2018 Dataset/1P68A01R1_spe...   0.034607  -0.034241   \n",
       "2     spectrograms/4 July 2018 Dataset/5P60A05R1_spe...  -0.086121   0.089172   \n",
       "3     spectrograms/4 July 2018 Dataset/3P65A03R3_spe...  -0.034821   0.034851   \n",
       "4     spectrograms/4 July 2018 Dataset/1P62A01R2_spe...   0.058044  -0.131958   \n",
       "...                                                 ...        ...        ...   \n",
       "1749  spectrograms/1 December 2017 Dataset/6P56A06R0...  -0.045807  -0.061523   \n",
       "1750  spectrograms/1 December 2017 Dataset/1P42A01R0...   0.025467  -0.013214   \n",
       "1751  spectrograms/1 December 2017 Dataset/6P40A06R0...  -0.044037  -0.016708   \n",
       "1752  spectrograms/1 December 2017 Dataset/2P56A02R0...   0.064026  -0.040649   \n",
       "1753  spectrograms/Sample_data_preprocessing+label_e...   0.089233   0.015251   \n",
       "\n",
       "      feature_2  feature_3  feature_4  feature_5  feature_6  feature_7  \\\n",
       "0     -0.145508  -0.373291  -0.008018  -0.236084   0.068909   0.140747   \n",
       "1     -0.101257  -0.314209  -0.255371  -0.125732   0.016068  -0.000095   \n",
       "2     -0.174683  -0.426758  -0.082092  -0.114990  -0.052063   0.198975   \n",
       "3     -0.234253  -0.427246  -0.048126  -0.329834   0.031830   0.111877   \n",
       "4     -0.123047  -0.252197  -0.213013  -0.140991   0.030991  -0.042145   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1749  -0.045197  -0.329102  -0.037079  -0.083801  -0.027954   0.187988   \n",
       "1750  -0.195801  -0.453125  -0.275391  -0.149902  -0.021835   0.052521   \n",
       "1751  -0.088562  -0.362061  -0.119751  -0.167114  -0.026672   0.211792   \n",
       "1752  -0.171021  -0.335693  -0.171387  -0.112244  -0.003649   0.106323   \n",
       "1753  -0.126831  -0.284668  -0.037140  -0.150513   0.018188   0.124084   \n",
       "\n",
       "      feature_8  ...  mean_torso_power  pos_neg_ratio  doppler_offset  \\\n",
       "0     -0.217529  ...      6.303265e+07       0.151130       -0.231972   \n",
       "1     -0.256104  ...      1.235783e+07       0.558474       -0.234554   \n",
       "2     -0.243286  ...      1.745773e+06       1.047543        0.001466   \n",
       "3     -0.276123  ...      1.134535e+08       0.047521       -0.251409   \n",
       "4     -0.204224  ...      9.166222e+06       1.839353        0.272753   \n",
       "...         ...  ...               ...            ...             ...   \n",
       "1749  -0.169800  ...      3.642903e+06       0.016558       -0.585832   \n",
       "1750  -0.262939  ...      1.031794e+08       0.648905       -0.094934   \n",
       "1751  -0.144775  ...      1.974422e+07       0.014511       -0.433081   \n",
       "1752  -0.143188  ...      1.168200e+08      15.373221        0.264797   \n",
       "1753  -0.143188  ...      7.025300e+07       1.729300        0.041178   \n",
       "\n",
       "      main_lobe_width  motion_duration  doppler_peak_velocity  \\\n",
       "0            0.161638             0.31              -0.193966   \n",
       "1            0.420259             0.53              -0.872845   \n",
       "2            0.323276             0.05               0.129310   \n",
       "3            0.129310             0.13              -0.161638   \n",
       "4            0.258621             0.93               0.905172   \n",
       "...               ...              ...                    ...   \n",
       "1749         0.193966             0.14              -0.517241   \n",
       "1750         1.745690             2.90              -0.743534   \n",
       "1751         0.129310             0.31              -0.355603   \n",
       "1752         0.161638             0.25               0.161638   \n",
       "1753         0.096983             0.22               0.129310   \n",
       "\n",
       "      doppler_symmetry_index  cepstral_entropy  range_bin_span  \\\n",
       "0                  -0.737423          1.083437             6.0   \n",
       "1                  -0.283306          0.909129            12.0   \n",
       "2                   0.023219          0.410934             8.0   \n",
       "3                  -0.909270          1.122153             6.0   \n",
       "4                   0.295614          0.826051            10.0   \n",
       "...                      ...               ...             ...   \n",
       "1749               -0.967423          1.140569             5.0   \n",
       "1750               -0.212926          0.960106             6.0   \n",
       "1751               -0.971394          1.054593             6.0   \n",
       "1752                0.877849          1.310697             5.0   \n",
       "1753                0.267211          1.095919             2.0   \n",
       "\n",
       "      doppler_bandwidth  \n",
       "0              0.236668  \n",
       "1              0.832668  \n",
       "2              0.762034  \n",
       "3              0.204580  \n",
       "4              0.963742  \n",
       "...                 ...  \n",
       "1749           0.293774  \n",
       "1750           0.736956  \n",
       "1751           0.330681  \n",
       "1752           0.270219  \n",
       "1753           0.195418  \n",
       "\n",
       "[1754 rows x 791 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d022ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the activity column like this \n",
    "ACTIVITY_MAP = {\n",
    "    \"walking\": 1,\n",
    "    \"sitting_down\": 2,\n",
    "    \"standing_up\": 3,\n",
    "    \"pick_object\": 4,\n",
    "    \"drink_water\": 5,\n",
    "    \"fall\": 6,\n",
    "}\n",
    "merged_df['activity'] = merged_df['activity'].map(ACTIVITY_MAP)\n",
    "\n",
    "merged_df=merged_df.drop(columns=['path', 'file_id', 'image_path'])  # drop unnecessary columns\n",
    "#split in train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_df.drop(columns=['activity']),\n",
    "                                                    merged_df['activity'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=merged_df['activity'])\n",
    "#validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                  y_train,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42,\n",
    "                                                  stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb8eb62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     walking       1.00      0.98      0.99        62\n",
      "sitting_down       0.95      0.97      0.96        63\n",
      " standing_up       0.92      0.95      0.94        62\n",
      " pick_object       0.73      0.77      0.75        62\n",
      " drink_water       0.79      0.74      0.77        62\n",
      "        fall       0.97      0.93      0.95        40\n",
      "\n",
      "    accuracy                           0.89       351\n",
      "   macro avg       0.89      0.89      0.89       351\n",
      "weighted avg       0.89      0.89      0.89       351\n",
      "\n",
      "Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "#randomforest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "#fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#evaluate the model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=ACTIVITY_MAP.keys()))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed4c195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.98      0.99        62\n",
      "           2       0.95      0.97      0.96        63\n",
      "           3       0.92      0.95      0.94        62\n",
      "           4       0.73      0.77      0.75        62\n",
      "           5       0.79      0.74      0.77        62\n",
      "           6       0.97      0.93      0.95        40\n",
      "\n",
      "    accuracy                           0.89       351\n",
      "   macro avg       0.89      0.89      0.89       351\n",
      "weighted avg       0.89      0.89      0.89       351\n",
      "\n",
      "Accuracy with scaled features: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "#standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "#fit the model again with scaled features\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "#evaluate the model again\n",
    "y_pred_scaled = rf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_scaled))\n",
    "print(\"Accuracy with scaled features:\", accuracy_score(y_test, y_pred_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff3f219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.97      0.98        62\n",
      "           2       0.83      0.78      0.80        63\n",
      "           3       0.72      0.77      0.74        62\n",
      "           4       0.65      0.68      0.66        62\n",
      "           5       0.66      0.68      0.67        62\n",
      "           6       0.94      0.85      0.89        40\n",
      "\n",
      "    accuracy                           0.78       351\n",
      "   macro avg       0.80      0.79      0.79       351\n",
      "weighted avg       0.79      0.78      0.79       351\n",
      "\n",
      "Accuracy with PCA features: 0.7834757834757835\n"
     ]
    }
   ],
   "source": [
    "#PCA for dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30)  # retain 95% of variance\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "#fit the model again with PCA features\n",
    "rf.fit(X_train_pca, y_train)\n",
    "#evaluate the model again\n",
    "y_pred_pca = rf.predict(X_test_pca)\n",
    "print(classification_report(y_test, y_pred_pca))\n",
    "print(\"Accuracy with PCA features:\", accuracy_score(y_test, y_pred_pca))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a0a7259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 787 features.\n",
      "Fitting estimator with 786 features.\n",
      "Fitting estimator with 785 features.\n",
      "Fitting estimator with 784 features.\n",
      "Fitting estimator with 783 features.\n",
      "Fitting estimator with 782 features.\n",
      "Fitting estimator with 781 features.\n",
      "Fitting estimator with 780 features.\n",
      "Fitting estimator with 779 features.\n",
      "Fitting estimator with 778 features.\n",
      "Fitting estimator with 777 features.\n",
      "Fitting estimator with 776 features.\n",
      "Fitting estimator with 775 features.\n",
      "Fitting estimator with 774 features.\n",
      "Fitting estimator with 773 features.\n",
      "Fitting estimator with 772 features.\n",
      "Fitting estimator with 771 features.\n",
      "Fitting estimator with 770 features.\n",
      "Fitting estimator with 769 features.\n",
      "Fitting estimator with 768 features.\n",
      "Fitting estimator with 767 features.\n",
      "Fitting estimator with 766 features.\n",
      "Fitting estimator with 765 features.\n",
      "Fitting estimator with 764 features.\n",
      "Fitting estimator with 763 features.\n",
      "Fitting estimator with 762 features.\n",
      "Fitting estimator with 761 features.\n",
      "Fitting estimator with 760 features.\n",
      "Fitting estimator with 759 features.\n",
      "Fitting estimator with 758 features.\n",
      "Fitting estimator with 757 features.\n",
      "Fitting estimator with 756 features.\n",
      "Fitting estimator with 755 features.\n",
      "Fitting estimator with 754 features.\n",
      "Fitting estimator with 753 features.\n",
      "Fitting estimator with 752 features.\n",
      "Fitting estimator with 751 features.\n",
      "Fitting estimator with 750 features.\n",
      "Fitting estimator with 749 features.\n",
      "Fitting estimator with 748 features.\n",
      "Fitting estimator with 747 features.\n",
      "Fitting estimator with 746 features.\n",
      "Fitting estimator with 745 features.\n",
      "Fitting estimator with 744 features.\n",
      "Fitting estimator with 743 features.\n",
      "Fitting estimator with 742 features.\n",
      "Fitting estimator with 741 features.\n",
      "Fitting estimator with 740 features.\n",
      "Fitting estimator with 739 features.\n",
      "Fitting estimator with 738 features.\n",
      "Fitting estimator with 737 features.\n",
      "Fitting estimator with 736 features.\n",
      "Fitting estimator with 735 features.\n",
      "Fitting estimator with 734 features.\n",
      "Fitting estimator with 733 features.\n",
      "Fitting estimator with 732 features.\n",
      "Fitting estimator with 731 features.\n",
      "Fitting estimator with 730 features.\n",
      "Fitting estimator with 729 features.\n",
      "Fitting estimator with 728 features.\n",
      "Fitting estimator with 727 features.\n",
      "Fitting estimator with 726 features.\n",
      "Fitting estimator with 725 features.\n",
      "Fitting estimator with 724 features.\n",
      "Fitting estimator with 723 features.\n",
      "Fitting estimator with 722 features.\n",
      "Fitting estimator with 721 features.\n",
      "Fitting estimator with 720 features.\n",
      "Fitting estimator with 719 features.\n",
      "Fitting estimator with 718 features.\n",
      "Fitting estimator with 717 features.\n",
      "Fitting estimator with 716 features.\n",
      "Fitting estimator with 715 features.\n",
      "Fitting estimator with 714 features.\n",
      "Fitting estimator with 713 features.\n",
      "Fitting estimator with 712 features.\n",
      "Fitting estimator with 711 features.\n",
      "Fitting estimator with 710 features.\n",
      "Fitting estimator with 709 features.\n",
      "Fitting estimator with 708 features.\n",
      "Fitting estimator with 707 features.\n",
      "Fitting estimator with 706 features.\n",
      "Fitting estimator with 705 features.\n",
      "Fitting estimator with 704 features.\n",
      "Fitting estimator with 703 features.\n",
      "Fitting estimator with 702 features.\n",
      "Fitting estimator with 701 features.\n",
      "Fitting estimator with 700 features.\n",
      "Fitting estimator with 699 features.\n",
      "Fitting estimator with 698 features.\n",
      "Fitting estimator with 697 features.\n",
      "Fitting estimator with 696 features.\n",
      "Fitting estimator with 695 features.\n",
      "Fitting estimator with 694 features.\n",
      "Fitting estimator with 693 features.\n",
      "Fitting estimator with 692 features.\n",
      "Fitting estimator with 691 features.\n",
      "Fitting estimator with 690 features.\n",
      "Fitting estimator with 689 features.\n",
      "Fitting estimator with 688 features.\n",
      "Fitting estimator with 687 features.\n",
      "Fitting estimator with 686 features.\n",
      "Fitting estimator with 685 features.\n",
      "Fitting estimator with 684 features.\n",
      "Fitting estimator with 683 features.\n",
      "Fitting estimator with 682 features.\n",
      "Fitting estimator with 681 features.\n",
      "Fitting estimator with 680 features.\n",
      "Fitting estimator with 679 features.\n",
      "Fitting estimator with 678 features.\n",
      "Fitting estimator with 677 features.\n",
      "Fitting estimator with 676 features.\n",
      "Fitting estimator with 675 features.\n",
      "Fitting estimator with 674 features.\n",
      "Fitting estimator with 673 features.\n",
      "Fitting estimator with 672 features.\n",
      "Fitting estimator with 671 features.\n",
      "Fitting estimator with 670 features.\n",
      "Fitting estimator with 669 features.\n",
      "Fitting estimator with 668 features.\n",
      "Fitting estimator with 667 features.\n",
      "Fitting estimator with 666 features.\n",
      "Fitting estimator with 665 features.\n",
      "Fitting estimator with 664 features.\n",
      "Fitting estimator with 663 features.\n",
      "Fitting estimator with 662 features.\n",
      "Fitting estimator with 661 features.\n",
      "Fitting estimator with 660 features.\n",
      "Fitting estimator with 659 features.\n",
      "Fitting estimator with 658 features.\n",
      "Fitting estimator with 657 features.\n",
      "Fitting estimator with 656 features.\n",
      "Fitting estimator with 655 features.\n",
      "Fitting estimator with 654 features.\n",
      "Fitting estimator with 653 features.\n",
      "Fitting estimator with 652 features.\n",
      "Fitting estimator with 651 features.\n",
      "Fitting estimator with 650 features.\n",
      "Fitting estimator with 649 features.\n",
      "Fitting estimator with 648 features.\n",
      "Fitting estimator with 647 features.\n",
      "Fitting estimator with 646 features.\n",
      "Fitting estimator with 645 features.\n",
      "Fitting estimator with 644 features.\n",
      "Fitting estimator with 643 features.\n",
      "Fitting estimator with 642 features.\n",
      "Fitting estimator with 641 features.\n",
      "Fitting estimator with 640 features.\n",
      "Fitting estimator with 639 features.\n",
      "Fitting estimator with 638 features.\n",
      "Fitting estimator with 637 features.\n",
      "Fitting estimator with 636 features.\n",
      "Fitting estimator with 635 features.\n",
      "Fitting estimator with 634 features.\n",
      "Fitting estimator with 633 features.\n",
      "Fitting estimator with 632 features.\n",
      "Fitting estimator with 631 features.\n",
      "Fitting estimator with 630 features.\n",
      "Fitting estimator with 629 features.\n",
      "Fitting estimator with 628 features.\n",
      "Fitting estimator with 627 features.\n",
      "Fitting estimator with 626 features.\n",
      "Fitting estimator with 625 features.\n",
      "Fitting estimator with 624 features.\n",
      "Fitting estimator with 623 features.\n",
      "Fitting estimator with 622 features.\n",
      "Fitting estimator with 621 features.\n",
      "Fitting estimator with 620 features.\n",
      "Fitting estimator with 619 features.\n",
      "Fitting estimator with 618 features.\n",
      "Fitting estimator with 617 features.\n",
      "Fitting estimator with 616 features.\n",
      "Fitting estimator with 615 features.\n",
      "Fitting estimator with 614 features.\n",
      "Fitting estimator with 613 features.\n",
      "Fitting estimator with 612 features.\n",
      "Fitting estimator with 611 features.\n",
      "Fitting estimator with 610 features.\n",
      "Fitting estimator with 609 features.\n",
      "Fitting estimator with 608 features.\n",
      "Fitting estimator with 607 features.\n",
      "Fitting estimator with 606 features.\n",
      "Fitting estimator with 605 features.\n",
      "Fitting estimator with 604 features.\n",
      "Fitting estimator with 603 features.\n",
      "Fitting estimator with 602 features.\n",
      "Fitting estimator with 601 features.\n",
      "Fitting estimator with 600 features.\n",
      "Fitting estimator with 599 features.\n",
      "Fitting estimator with 598 features.\n",
      "Fitting estimator with 597 features.\n",
      "Fitting estimator with 596 features.\n",
      "Fitting estimator with 595 features.\n",
      "Fitting estimator with 594 features.\n",
      "Fitting estimator with 593 features.\n",
      "Fitting estimator with 592 features.\n",
      "Fitting estimator with 591 features.\n",
      "Fitting estimator with 590 features.\n",
      "Fitting estimator with 589 features.\n",
      "Fitting estimator with 588 features.\n",
      "Fitting estimator with 587 features.\n",
      "Fitting estimator with 586 features.\n",
      "Fitting estimator with 585 features.\n",
      "Fitting estimator with 584 features.\n",
      "Fitting estimator with 583 features.\n",
      "Fitting estimator with 582 features.\n",
      "Fitting estimator with 581 features.\n",
      "Fitting estimator with 580 features.\n",
      "Fitting estimator with 579 features.\n",
      "Fitting estimator with 578 features.\n",
      "Fitting estimator with 577 features.\n",
      "Fitting estimator with 576 features.\n",
      "Fitting estimator with 575 features.\n",
      "Fitting estimator with 574 features.\n",
      "Fitting estimator with 573 features.\n",
      "Fitting estimator with 572 features.\n",
      "Fitting estimator with 571 features.\n",
      "Fitting estimator with 570 features.\n",
      "Fitting estimator with 569 features.\n",
      "Fitting estimator with 568 features.\n",
      "Fitting estimator with 567 features.\n",
      "Fitting estimator with 566 features.\n",
      "Fitting estimator with 565 features.\n",
      "Fitting estimator with 564 features.\n",
      "Fitting estimator with 563 features.\n",
      "Fitting estimator with 562 features.\n",
      "Fitting estimator with 561 features.\n",
      "Fitting estimator with 560 features.\n",
      "Fitting estimator with 559 features.\n",
      "Fitting estimator with 558 features.\n",
      "Fitting estimator with 557 features.\n",
      "Fitting estimator with 556 features.\n",
      "Fitting estimator with 555 features.\n",
      "Fitting estimator with 554 features.\n",
      "Fitting estimator with 553 features.\n",
      "Fitting estimator with 552 features.\n",
      "Fitting estimator with 551 features.\n",
      "Fitting estimator with 550 features.\n",
      "Fitting estimator with 549 features.\n",
      "Fitting estimator with 548 features.\n",
      "Fitting estimator with 547 features.\n",
      "Fitting estimator with 546 features.\n",
      "Fitting estimator with 545 features.\n",
      "Fitting estimator with 544 features.\n",
      "Fitting estimator with 543 features.\n",
      "Fitting estimator with 542 features.\n",
      "Fitting estimator with 541 features.\n",
      "Fitting estimator with 540 features.\n",
      "Fitting estimator with 539 features.\n",
      "Fitting estimator with 538 features.\n",
      "Fitting estimator with 537 features.\n",
      "Fitting estimator with 536 features.\n",
      "Fitting estimator with 535 features.\n",
      "Fitting estimator with 534 features.\n",
      "Fitting estimator with 533 features.\n",
      "Fitting estimator with 532 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 530 features.\n",
      "Fitting estimator with 529 features.\n",
      "Fitting estimator with 528 features.\n",
      "Fitting estimator with 527 features.\n",
      "Fitting estimator with 526 features.\n",
      "Fitting estimator with 525 features.\n",
      "Fitting estimator with 524 features.\n",
      "Fitting estimator with 523 features.\n",
      "Fitting estimator with 522 features.\n",
      "Fitting estimator with 521 features.\n",
      "Fitting estimator with 520 features.\n",
      "Fitting estimator with 519 features.\n",
      "Fitting estimator with 518 features.\n",
      "Fitting estimator with 517 features.\n",
      "Fitting estimator with 516 features.\n",
      "Fitting estimator with 515 features.\n",
      "Fitting estimator with 514 features.\n",
      "Fitting estimator with 513 features.\n",
      "Fitting estimator with 512 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 510 features.\n",
      "Fitting estimator with 509 features.\n",
      "Fitting estimator with 508 features.\n",
      "Fitting estimator with 507 features.\n",
      "Fitting estimator with 506 features.\n",
      "Fitting estimator with 505 features.\n",
      "Fitting estimator with 504 features.\n",
      "Fitting estimator with 503 features.\n",
      "Fitting estimator with 502 features.\n",
      "Fitting estimator with 501 features.\n",
      "Fitting estimator with 500 features.\n",
      "Fitting estimator with 499 features.\n",
      "Fitting estimator with 498 features.\n",
      "Fitting estimator with 497 features.\n",
      "Fitting estimator with 496 features.\n",
      "Fitting estimator with 495 features.\n",
      "Fitting estimator with 494 features.\n",
      "Fitting estimator with 493 features.\n",
      "Fitting estimator with 492 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 490 features.\n",
      "Fitting estimator with 489 features.\n",
      "Fitting estimator with 488 features.\n",
      "Fitting estimator with 487 features.\n",
      "Fitting estimator with 486 features.\n",
      "Fitting estimator with 485 features.\n",
      "Fitting estimator with 484 features.\n",
      "Fitting estimator with 483 features.\n",
      "Fitting estimator with 482 features.\n",
      "Fitting estimator with 481 features.\n",
      "Fitting estimator with 480 features.\n",
      "Fitting estimator with 479 features.\n",
      "Fitting estimator with 478 features.\n",
      "Fitting estimator with 477 features.\n",
      "Fitting estimator with 476 features.\n",
      "Fitting estimator with 475 features.\n",
      "Fitting estimator with 474 features.\n",
      "Fitting estimator with 473 features.\n",
      "Fitting estimator with 472 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 470 features.\n",
      "Fitting estimator with 469 features.\n",
      "Fitting estimator with 468 features.\n",
      "Fitting estimator with 467 features.\n",
      "Fitting estimator with 466 features.\n",
      "Fitting estimator with 465 features.\n",
      "Fitting estimator with 464 features.\n",
      "Fitting estimator with 463 features.\n",
      "Fitting estimator with 462 features.\n",
      "Fitting estimator with 461 features.\n",
      "Fitting estimator with 460 features.\n",
      "Fitting estimator with 459 features.\n",
      "Fitting estimator with 458 features.\n",
      "Fitting estimator with 457 features.\n",
      "Fitting estimator with 456 features.\n",
      "Fitting estimator with 455 features.\n",
      "Fitting estimator with 454 features.\n",
      "Fitting estimator with 453 features.\n",
      "Fitting estimator with 452 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 450 features.\n",
      "Fitting estimator with 449 features.\n",
      "Fitting estimator with 448 features.\n",
      "Fitting estimator with 447 features.\n",
      "Fitting estimator with 446 features.\n",
      "Fitting estimator with 445 features.\n",
      "Fitting estimator with 444 features.\n",
      "Fitting estimator with 443 features.\n",
      "Fitting estimator with 442 features.\n",
      "Fitting estimator with 441 features.\n",
      "Fitting estimator with 440 features.\n",
      "Fitting estimator with 439 features.\n",
      "Fitting estimator with 438 features.\n",
      "Fitting estimator with 437 features.\n",
      "Fitting estimator with 436 features.\n",
      "Fitting estimator with 435 features.\n",
      "Fitting estimator with 434 features.\n",
      "Fitting estimator with 433 features.\n",
      "Fitting estimator with 432 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 430 features.\n",
      "Fitting estimator with 429 features.\n",
      "Fitting estimator with 428 features.\n",
      "Fitting estimator with 427 features.\n",
      "Fitting estimator with 426 features.\n",
      "Fitting estimator with 425 features.\n",
      "Fitting estimator with 424 features.\n",
      "Fitting estimator with 423 features.\n",
      "Fitting estimator with 422 features.\n",
      "Fitting estimator with 421 features.\n",
      "Fitting estimator with 420 features.\n",
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 418 features.\n",
      "Fitting estimator with 417 features.\n",
      "Fitting estimator with 416 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 414 features.\n",
      "Fitting estimator with 413 features.\n",
      "Fitting estimator with 412 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 410 features.\n",
      "Fitting estimator with 409 features.\n",
      "Fitting estimator with 408 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 406 features.\n",
      "Fitting estimator with 405 features.\n",
      "Fitting estimator with 404 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 402 features.\n",
      "Fitting estimator with 401 features.\n",
      "Fitting estimator with 400 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 398 features.\n",
      "Fitting estimator with 397 features.\n",
      "Fitting estimator with 396 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 394 features.\n",
      "Fitting estimator with 393 features.\n",
      "Fitting estimator with 392 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 390 features.\n",
      "Fitting estimator with 389 features.\n",
      "Fitting estimator with 388 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 386 features.\n",
      "Fitting estimator with 385 features.\n",
      "Fitting estimator with 384 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 382 features.\n",
      "Fitting estimator with 381 features.\n",
      "Fitting estimator with 380 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 378 features.\n",
      "Fitting estimator with 377 features.\n",
      "Fitting estimator with 376 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 374 features.\n",
      "Fitting estimator with 373 features.\n",
      "Fitting estimator with 372 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 370 features.\n",
      "Fitting estimator with 369 features.\n",
      "Fitting estimator with 368 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 366 features.\n",
      "Fitting estimator with 365 features.\n",
      "Fitting estimator with 364 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 362 features.\n",
      "Fitting estimator with 361 features.\n",
      "Fitting estimator with 360 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 358 features.\n",
      "Fitting estimator with 357 features.\n",
      "Fitting estimator with 356 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 354 features.\n",
      "Fitting estimator with 353 features.\n",
      "Fitting estimator with 352 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 350 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 348 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 346 features.\n",
      "Fitting estimator with 345 features.\n",
      "Fitting estimator with 344 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 342 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 340 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 338 features.\n",
      "Fitting estimator with 337 features.\n",
      "Fitting estimator with 336 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 334 features.\n",
      "Fitting estimator with 333 features.\n",
      "Fitting estimator with 332 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 330 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 328 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 326 features.\n",
      "Fitting estimator with 325 features.\n",
      "Fitting estimator with 324 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 322 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 320 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 318 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 314 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 310 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 304 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 302 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 292 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 290 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 284 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Selected features: ['feature_2', 'feature_8', 'feature_13', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_27', 'feature_29', 'feature_34', 'feature_40', 'feature_41', 'feature_50', 'feature_61', 'feature_62', 'feature_64', 'feature_66', 'feature_67', 'feature_72', 'feature_79', 'feature_82', 'feature_84', 'feature_87', 'feature_89', 'feature_90', 'feature_92', 'feature_108', 'feature_114', 'feature_116', 'feature_120', 'feature_127', 'feature_128', 'feature_132', 'feature_136', 'feature_137', 'feature_138', 'feature_141', 'feature_150', 'feature_151', 'feature_157', 'feature_159', 'feature_164', 'feature_165', 'feature_166', 'feature_170', 'feature_172', 'feature_176', 'feature_180', 'feature_182', 'feature_184', 'feature_185', 'feature_186', 'feature_190', 'feature_192', 'feature_198', 'feature_204', 'feature_205', 'feature_210', 'feature_213', 'feature_214', 'feature_221', 'feature_225', 'feature_229', 'feature_233', 'feature_234', 'feature_240', 'feature_243', 'feature_254', 'feature_256', 'feature_257', 'feature_262', 'feature_266', 'feature_267', 'feature_269', 'feature_270', 'feature_275', 'feature_276', 'feature_278', 'feature_279', 'feature_284', 'feature_288', 'feature_293', 'feature_297', 'feature_298', 'feature_301', 'feature_306', 'feature_308', 'feature_309', 'feature_311', 'feature_314', 'feature_315', 'feature_319', 'feature_324', 'feature_328', 'feature_331', 'feature_334', 'feature_336', 'feature_337', 'feature_340', 'feature_342', 'feature_344', 'feature_353', 'feature_356', 'feature_357', 'feature_367', 'feature_371', 'feature_375', 'feature_377', 'feature_380', 'feature_381', 'feature_383', 'feature_385', 'feature_387', 'feature_389', 'feature_390', 'feature_395', 'feature_396', 'feature_407', 'feature_408', 'feature_409', 'feature_413', 'feature_415', 'feature_418', 'feature_426', 'feature_427', 'feature_430', 'feature_432', 'feature_441', 'feature_444', 'feature_448', 'feature_452', 'feature_462', 'feature_465', 'feature_466', 'feature_467', 'feature_477', 'feature_479', 'feature_483', 'feature_486', 'feature_489', 'feature_492', 'feature_497', 'feature_498', 'feature_500', 'feature_504', 'feature_512', 'feature_515', 'feature_521', 'feature_524', 'feature_527', 'feature_538', 'feature_541', 'feature_544', 'feature_547', 'feature_550', 'feature_552', 'feature_556', 'feature_557', 'feature_558', 'feature_564', 'feature_565', 'feature_570', 'feature_574', 'feature_579', 'feature_580', 'feature_581', 'feature_582', 'feature_584', 'feature_587', 'feature_589', 'feature_596', 'feature_597', 'feature_605', 'feature_614', 'feature_617', 'feature_620', 'feature_624', 'feature_629', 'feature_630', 'feature_639', 'feature_650', 'feature_651', 'feature_654', 'feature_656', 'feature_665', 'feature_667', 'feature_668', 'feature_671', 'feature_673', 'feature_679', 'feature_685', 'feature_690', 'feature_695', 'feature_705', 'feature_712', 'feature_714', 'feature_718', 'feature_719', 'feature_724', 'feature_732', 'feature_735', 'feature_737', 'feature_741', 'feature_747', 'feature_748', 'feature_753', 'feature_756', 'feature_760', 'feature_765', 'feature_766', 'mean_entropy', 'mean_power', 'variance', 'stddev', 'max_vel', 'periodicity', 'mean_torso_power', 'pos_neg_ratio', 'doppler_offset', 'main_lobe_width', 'doppler_peak_velocity', 'doppler_symmetry_index', 'cepstral_entropy', 'doppler_bandwidth']\n"
     ]
    }
   ],
   "source": [
    "#leave one out feature search\n",
    "from sklearn.feature_selection import RFECV\n",
    "selector = RFECV(estimator=rf, step=1, cv=5, scoring='accuracy', verbose = 4, n_jobs=-1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[selector.support_]\n",
    "print(\"Selected features:\", selected_features.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04581883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep selected features\n",
    "#Selected features: ['feature_2', 'feature_8', 'feature_13', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_27', 'feature_29', 'feature_34', 'feature_40', 'feature_41', 'feature_50', 'feature_61', 'feature_62', 'feature_64', 'feature_66', 'feature_67', 'feature_72', 'feature_79', 'feature_82', 'feature_84', 'feature_87', 'feature_89', 'feature_90', 'feature_92', 'feature_108', 'feature_114', 'feature_116', 'feature_120', 'feature_127', 'feature_128', 'feature_132', 'feature_136', 'feature_137', 'feature_138', 'feature_141', 'feature_150', 'feature_151', 'feature_157', 'feature_159', 'feature_164', 'feature_165', 'feature_166', 'feature_170', 'feature_172', 'feature_176', 'feature_180', 'feature_182', 'feature_184', 'feature_185', 'feature_186', 'feature_190', 'feature_192', 'feature_198', 'feature_204', 'feature_205', 'feature_210', 'feature_213', 'feature_214', 'feature_221', 'feature_225', 'feature_229', 'feature_233', 'feature_234', 'feature_240', 'feature_243', 'feature_254', 'feature_256', 'feature_257', 'feature_262', 'feature_266', 'feature_267', 'feature_269', 'feature_270', 'feature_275', 'feature_276', 'feature_278', 'feature_279', 'feature_284', 'feature_288', 'feature_293', 'feature_297', 'feature_298', 'feature_301', 'feature_306', 'feature_308', 'feature_309', 'feature_311', 'feature_314', 'feature_315', 'feature_319', 'feature_324', 'feature_328', 'feature_331', 'feature_334', 'feature_336', 'feature_337', 'feature_340', 'feature_342', 'feature_344', 'feature_353', 'feature_356', 'feature_357', 'feature_367', 'feature_371', 'feature_375', 'feature_377', 'feature_380', 'feature_381', 'feature_383', 'feature_385', 'feature_387', 'feature_389', 'feature_390', 'feature_395', 'feature_396', 'feature_407', 'feature_408', 'feature_409', 'feature_413', 'feature_415', 'feature_418', 'feature_426', 'feature_427', 'feature_430', 'feature_432', 'feature_441', 'feature_444', 'feature_448', 'feature_452', 'feature_462', 'feature_465', 'feature_466', 'feature_467', 'feature_477', 'feature_479', 'feature_483', 'feature_486', 'feature_489', 'feature_492', 'feature_497', 'feature_498', 'feature_500', 'feature_504', 'feature_512', 'feature_515', 'feature_521', 'feature_524', 'feature_527', 'feature_538', 'feature_541', 'feature_544', 'feature_547', 'feature_550', 'feature_552', 'feature_556', 'feature_557', 'feature_558', 'feature_564', 'feature_565', 'feature_570', 'feature_574', 'feature_579', 'feature_580', 'feature_581', 'feature_582', 'feature_584', 'feature_587', 'feature_589', 'feature_596', 'feature_597', 'feature_605', 'feature_614', 'feature_617', 'feature_620', 'feature_624', 'feature_629', 'feature_630', 'feature_639', 'feature_650', 'feature_651', 'feature_654', 'feature_656', 'feature_665', 'feature_667', 'feature_668', 'feature_671', 'feature_673', 'feature_679', 'feature_685', 'feature_690', 'feature_695', 'feature_705', 'feature_712', 'feature_714', 'feature_718', 'feature_719', 'feature_724', 'feature_732', 'feature_735', 'feature_737', 'feature_741', 'feature_747', 'feature_748', 'feature_753', 'feature_756', 'feature_760', 'feature_765', 'feature_766', 'mean_entropy', 'mean_power', 'variance', 'stddev', 'max_vel', 'periodicity', 'mean_torso_power', 'pos_neg_ratio', 'doppler_offset', 'main_lobe_width', 'doppler_peak_velocity', 'doppler_symmetry_index', 'cepstral_entropy', 'doppler_bandwidth']\n",
    "\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n",
    "X_val = X_val[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b8dee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.98      0.99        62\n",
      "           2       0.95      0.97      0.96        63\n",
      "           3       0.91      0.94      0.92        62\n",
      "           4       0.72      0.77      0.74        62\n",
      "           5       0.79      0.73      0.76        62\n",
      "           6       0.97      0.93      0.95        40\n",
      "\n",
      "    accuracy                           0.88       351\n",
      "   macro avg       0.89      0.89      0.89       351\n",
      "weighted avg       0.88      0.88      0.88       351\n",
      "\n",
      "Accuracy with selected features: 0.8831908831908832\n"
     ]
    }
   ],
   "source": [
    "#random forest classifier with selected features\n",
    "rf.fit(X_train, y_train)\n",
    "#evaluate the model with selected features\n",
    "y_pred_selected = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_selected))\n",
    "print(\"Accuracy with selected features:\", accuracy_score(y_test, y_pred_selected))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4f41de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.98      0.99        62\n",
      "           2       0.93      0.98      0.95        63\n",
      "           3       0.97      0.97      0.97        62\n",
      "           4       0.69      0.79      0.74        62\n",
      "           5       0.78      0.65      0.71        62\n",
      "           6       0.97      0.95      0.96        40\n",
      "\n",
      "    accuracy                           0.88       351\n",
      "   macro avg       0.89      0.89      0.89       351\n",
      "weighted avg       0.89      0.88      0.88       351\n",
      "\n",
      "MLP Accuracy: 0.8831908831908832\n"
     ]
    }
   ],
   "source": [
    "#MLP classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "#fit the model\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "#evaluate the model\n",
    "y_pred_mlp = mlp.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "print(\"MLP Accuracy:\", accuracy_score(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b25e54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_train_tensor: tensor([0, 1, 2, 3, 4, 5])\n",
      "Unique values in y_val_tensor: tensor([0, 1, 2, 3, 4, 5])\n",
      "Unique values in y_test_tensor: tensor([0, 1, 2, 3, 4, 5])\n",
      "num_classes: 6\n",
      "X_train_tensor has NaNs: tensor(False)\n",
      "X_train_tensor has Infs: tensor(False)\n",
      "X_val_tensor has NaNs: tensor(False)\n",
      "X_val_tensor has Infs: tensor(False)\n",
      "X_test_tensor has NaNs: tensor(False)\n",
      "X_test_tensor has Infs: tensor(False)\n",
      "Using device: cuda\n",
      "Epoch [1/5000], Loss: 1.1320, Val Loss: 0.6731\n",
      "Epoch [2/5000], Loss: 0.6543, Val Loss: 0.5355\n",
      "Epoch [3/5000], Loss: 0.5524, Val Loss: 0.4800\n",
      "Epoch [4/5000], Loss: 0.4963, Val Loss: 0.4581\n",
      "Epoch [5/5000], Loss: 0.4494, Val Loss: 0.4516\n",
      "Epoch [6/5000], Loss: 0.4242, Val Loss: 0.4367\n",
      "Epoch [7/5000], Loss: 0.3950, Val Loss: 0.4580\n",
      "Epoch [8/5000], Loss: 0.3736, Val Loss: 0.4286\n",
      "Epoch [9/5000], Loss: 0.3287, Val Loss: 0.4390\n",
      "Epoch [10/5000], Loss: 0.3333, Val Loss: 0.4255\n",
      "Epoch [11/5000], Loss: 0.3216, Val Loss: 0.4572\n",
      "Epoch [12/5000], Loss: 0.3122, Val Loss: 0.4296\n",
      "Epoch [13/5000], Loss: 0.2846, Val Loss: 0.4468\n",
      "Epoch [14/5000], Loss: 0.2769, Val Loss: 0.4293\n",
      "Epoch [15/5000], Loss: 0.2631, Val Loss: 0.4468\n",
      "Epoch [16/5000], Loss: 0.2539, Val Loss: 0.4322\n",
      "Epoch [17/5000], Loss: 0.2320, Val Loss: 0.4492\n",
      "Epoch [18/5000], Loss: 0.2501, Val Loss: 0.4684\n",
      "Epoch [19/5000], Loss: 0.2391, Val Loss: 0.4803\n",
      "Epoch [20/5000], Loss: 0.2175, Val Loss: 0.4845\n",
      "Epoch [21/5000], Loss: 0.2148, Val Loss: 0.4500\n",
      "Epoch [22/5000], Loss: 0.2099, Val Loss: 0.4771\n",
      "Epoch [23/5000], Loss: 0.2169, Val Loss: 0.4743\n",
      "Epoch [24/5000], Loss: 0.2166, Val Loss: 0.4935\n",
      "Epoch [25/5000], Loss: 0.2184, Val Loss: 0.4747\n",
      "Epoch [26/5000], Loss: 0.1996, Val Loss: 0.5000\n",
      "Epoch [27/5000], Loss: 0.1936, Val Loss: 0.5068\n",
      "Epoch [28/5000], Loss: 0.1786, Val Loss: 0.4971\n",
      "Epoch [29/5000], Loss: 0.1707, Val Loss: 0.5019\n",
      "Epoch [30/5000], Loss: 0.1697, Val Loss: 0.5117\n",
      "Epoch [31/5000], Loss: 0.1703, Val Loss: 0.5268\n",
      "Epoch [32/5000], Loss: 0.1668, Val Loss: 0.5111\n",
      "Epoch [33/5000], Loss: 0.1679, Val Loss: 0.5415\n",
      "Epoch [34/5000], Loss: 0.1351, Val Loss: 0.5268\n",
      "Epoch [35/5000], Loss: 0.1382, Val Loss: 0.5325\n",
      "Epoch [36/5000], Loss: 0.1678, Val Loss: 0.5178\n",
      "Epoch [37/5000], Loss: 0.1386, Val Loss: 0.5440\n",
      "Epoch [38/5000], Loss: 0.1449, Val Loss: 0.5523\n",
      "Epoch [39/5000], Loss: 0.1255, Val Loss: 0.5765\n",
      "Epoch [40/5000], Loss: 0.1200, Val Loss: 0.5933\n",
      "Epoch [41/5000], Loss: 0.1177, Val Loss: 0.5976\n",
      "Epoch [42/5000], Loss: 0.1361, Val Loss: 0.5870\n",
      "Epoch [43/5000], Loss: 0.1107, Val Loss: 0.5979\n",
      "Epoch [44/5000], Loss: 0.1144, Val Loss: 0.5985\n",
      "Epoch [45/5000], Loss: 0.1184, Val Loss: 0.5989\n",
      "Epoch [46/5000], Loss: 0.1158, Val Loss: 0.6089\n",
      "Epoch [47/5000], Loss: 0.1292, Val Loss: 0.6167\n",
      "Epoch [48/5000], Loss: 0.1170, Val Loss: 0.5950\n",
      "Epoch [49/5000], Loss: 0.0962, Val Loss: 0.5945\n",
      "Epoch [50/5000], Loss: 0.1120, Val Loss: 0.6145\n",
      "Epoch [51/5000], Loss: 0.1087, Val Loss: 0.6278\n",
      "Epoch [52/5000], Loss: 0.1009, Val Loss: 0.6645\n",
      "Epoch [53/5000], Loss: 0.1126, Val Loss: 0.6446\n",
      "Epoch [54/5000], Loss: 0.0933, Val Loss: 0.6214\n",
      "Epoch [55/5000], Loss: 0.0970, Val Loss: 0.6448\n",
      "Epoch [56/5000], Loss: 0.0952, Val Loss: 0.6438\n",
      "Epoch [57/5000], Loss: 0.0994, Val Loss: 0.6524\n",
      "Epoch [58/5000], Loss: 0.0869, Val Loss: 0.6794\n",
      "Epoch [59/5000], Loss: 0.0805, Val Loss: 0.7328\n",
      "Epoch [60/5000], Loss: 0.0918, Val Loss: 0.7296\n",
      "Early stopping triggered\n",
      "Loading best model from best_model.pth\n",
      "Test Loss: 0.3886, Test Accuracy: 0.8490\n",
      "Final model state saved to final_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adnane\\AppData\\Local\\Temp\\ipykernel_24760\\3199207767.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd # Assuming X_train_pca is a pandas DataFrame\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Encode labels to start from 0 using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# Fit on all unique labels across all sets to ensure consistency\n",
    "le.fit(np.unique(np.concatenate([y_train, y_val, y_test])))\n",
    "\n",
    "# Transform all label sets\n",
    "y_train_tensor = torch.tensor(le.transform(y_train), dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(le.transform(y_val), dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(le.transform(y_test), dtype=torch.long)\n",
    "\n",
    "# Define number of classes\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "# Debug: Check label ranges\n",
    "print(\"Unique values in y_train_tensor:\", torch.unique(y_train_tensor))\n",
    "print(\"Unique values in y_val_tensor:\", torch.unique(y_val_tensor))\n",
    "print(\"Unique values in y_test_tensor:\", torch.unique(y_test_tensor))\n",
    "print(\"num_classes:\", num_classes)\n",
    "\n",
    "# Assertions for label range (already present, good practice)\n",
    "assert torch.all(y_train_tensor >= 0) and torch.all(y_train_tensor < num_classes), \\\n",
    "    f\"y_train_tensor has out-of-range labels. Min: {y_train_tensor.min()}, Max: {y_train_tensor.max()}, Expected range [0, {num_classes-1}]\"\n",
    "assert torch.all(y_val_tensor >= 0) and torch.all(y_val_tensor < num_classes), \\\n",
    "    f\"y_val_tensor has out-of-range labels. Min: {y_val_tensor.min()}, Max: {y_val_tensor.max()}, Expected range [0, {num_classes-1}]\"\n",
    "assert torch.all(y_test_tensor >= 0) and torch.all(y_test_tensor < num_classes), \\\n",
    "    f\"y_test_tensor has out-of-range labels. Min: {y_test_tensor.min()}, Max: {y_test_tensor.max()}, Expected range [0, {num_classes-1}]\"\n",
    "\n",
    "\n",
    "# Convert PCA features to PyTorch tensors\n",
    "# Use directly if X_pca is a numpy array\n",
    "X_train_tensor = torch.tensor(X_train_pca, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_pca, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_pca, dtype=torch.float32)\n",
    "\n",
    "# Check for NaNs/Infs in input tensors\n",
    "print(\"X_train_tensor has NaNs:\", torch.isnan(X_train_tensor).any())\n",
    "print(\"X_train_tensor has Infs:\", torch.isinf(X_train_tensor).any())\n",
    "print(\"X_val_tensor has NaNs:\", torch.isnan(X_val_tensor).any())\n",
    "print(\"X_val_tensor has Infs:\", torch.isinf(X_val_tensor).any())\n",
    "print(\"X_test_tensor has NaNs:\", torch.isnan(X_test_tensor).any())\n",
    "print(\"X_test_tensor has Infs:\", torch.isinf(X_test_tensor).any())\n",
    "\n",
    "\n",
    "# Create DataLoader for training and validation sets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the neural network architecture\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x) # No activation here, as CrossEntropyLoss expects logits\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_size = X_train_pca.shape[1]\n",
    "model = SimpleNN(input_size, num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with early stopping\n",
    "num_epochs = 5000\n",
    "patience = 50\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "best_model_path = 'best_model.pth' # Define path for saving best model\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)  # Save best model\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "# Load best model for evaluation\n",
    "print(f\"Loading best model from {best_model_path}\")\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "with torch.no_grad():\n",
    "    test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=32)\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss /= len(X_test_tensor)\n",
    "test_accuracy = test_correct / len(X_test_tensor)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Save final model (optional, often you'd just use the best_model.pth for deployment)\n",
    "final_model_path = 'final_model.pth'\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f\"Final model state saved to {final_model_path}\")\n",
    "\n",
    "# Load model for inference (example)\n",
    "# loaded_model = SimpleNN(input_size, num_classes)\n",
    "# loaded_model.load_state_dict(torch.load('final_model.pth'))\n",
    "# loaded_model.to(device) # Don't forget to move it to device if you want to use it on GPU\n",
    "# loaded_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
